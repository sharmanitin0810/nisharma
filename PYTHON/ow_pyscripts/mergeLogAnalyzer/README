Log Data Correlation for Functinal Test Results Analysis
--------------------------------------------------------
This is a script that aggregates the data from multiple sources in a test run to provide comprehensive view of the test results.

The script merges the data from the following sources:
- Alarm History from the EMS for the test period
- Satellite Beam Handover Prediction Records
- UT Modem Log Files
- Ping Data transfer test result traces

The script performs the merge operation for each of the ping data transfer test result trace file and it merges the data from other 3 sources.
The script is to be given date as argument in <YYYY-MM-DD> format. The script searches for all the files in the date subfolder in the NAS drive, OAT folder 
(i.e., \\10.52.2.68\oat\<YYYY-MM-DD>). The data files can be in multiple sub directories beneath this root directory. The script recursively
traverses the subdirectories to pick up the desired files. For the ping data transfer test results file, it searches for files with names in the format
'UT<UTId>_PING*.txt'.

It picks up the start and stop time from an auxiliary file generated by the 'test automation framework' for each UT in the same directory as the ping results files. 
This file is present with the name in the format 'UT<UTID>_Log*.txt'. 

-----------------------------------------------------------
It fetches the alarm history
from the EMS for the given start and stop period. The alarms are fetched using REST API call with authentication token. If the EMS is not directly accessible
over one hop in the network, but available through two hops, the script sets up dynamic port forwarding through SOCKS proxy.

------------------------------------------------------------------
For the UT modem logs files for the specified time period, the script searches the files from the same root directory (i.e., \\10.52.2.68\oat\<YYYY-MM-DD>.
Note that UT modem files could also be in multiple subdirectories beneath the root directory. The script recursively traverses the subdirectories to pick the files
with the names in the format <SITENAME>_OAT_PTU_<UTID>_<MM-DD.HH-mm-ss-SSS>.txt. The <SITENAME> is either 'PMO' (for Palermo and CRO for Croatia).
The UTIDs in the UT modem log file names and the ping log file names does not have to be the same. The mapping between the two IDs are maintained in a 
dictionary in the script. The timestamp in the filename should be within the start and end time of the ping data transfer test result log file.
The text based log files are generated from the UT Modem .isf files using another script (isfConvert2Ascii.py) that has to be run in a machine which has the QXDM/QCAT are installed.

The script uses min heap based algorithm to efficiently merge ping log file, alarm list, satellite beam handover prediction records, UT modem logs.
It is expected that the entries in each of the files are sorted in chronilogical order. The script accepts different time formats for each of the file entries.
For UT modem log files, it only picks up the selected log entries, mainly related to RRC, NAS, Initial Access (MSG1-MSG4)and all events. It picks up few important fields
such as satellite, beam, TAC, TMSI, activation SFN, lat/log etc.for display along with the log entry.
For alarms, it also has the ability to exclude alarms specified in an alarm filter configuration file, if present in the above root directory with the name alarmFilterList.txt.

The merge log file will be stored in the same directory as the ping data transfer file against which the merge is done. The merge file will have the same name as the
ping data transfer file with the prefix 'MergeLog_". 

The log files can be viewed in an editor such as notepad+ with the support for syntax highlighting. A set of rules for formatting the output are developed that highlights critical events for eliciting attention in the display.
The rules are captured in 'displayHighlighter' file. This file can be imported to notepad++ under Language->User Defined Language->Import.

The script also generates a summary csv (UTSummaryStatus.csv) which provides the summary status of each UT in each satellite/beam for each ping data transfer test.
This provides a quick view to see which satellite/beams the UTs have issues and if they show up on multiple UTs for a given satellite/beam, it would possibly point to GN/satellite issues.

Installation Instructions:
-------------------------
The script is written in python 3.x and makes use of quite of lot of 3.x based libraries. Since python 2.x is not compatible with 3.x, the script should be run from python 3.x environment.
The script has been tested under the Windows environment. It may need some tweeks if has to be run under Linux environment.
The script makes use of following python libraries and hence these have to be installed.
> paramiko
> ans1tools
> python_dateutil

If not already installed, each of these libraries can be installed by 
> python -m pip install <above package name>

Run Instructions:
----------------
1. Prior to running the command, ensure that you have connectivity to the proxy server 10.52.4.4 (This for getting the alarm list from the field EMS)
2. Run the command: python mergeLogAnalyzer.py <YYYY-MM-DD>
3. The command can be run from a PC that has network connectivity to 10.52.2.68. If the script hangs, it is due to the script unable to connect to the NAS without username password. 
4. In that case, from the windows explorer window, go to \\10.52.4.68. It should open up pop up window asking for user name and password. Provide the username as 'msat' and password 'oneweb123'.
5. Once the access is successful, go back to step 2 to run the python mergeLogAnalyzer.py command
6. The script expects the input files (ie., ping results files, handover prediction files, UT modem logs text files) under subfolders of \\10.52.4.68\oat\<SpecifiedDate>.
7. The script should generate the merged output logs in the same sub folder as the input subfolder of ping result files.
8. The summary csv file (UTSummaryStatus.csv) is generated at \\10.52.4.68\oat\<SpecifiedDate> 
9. Note that if the script is run multiple times, it overwrites the previous merged files.
10. Open up the output file in the notepad++. Under Language tab, select the 'logHighlight' if already present, if not, import the 'displayHighLighter' file and select it. This should highlight critical events 
in the logs with different color. 
